{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa6bd703-bc1c-4b24-ad9f-5517e78aa566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-probability in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (0.19.0)\n",
      "Requirement already satisfied: decorator in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-probability) (5.1.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-probability) (1.16.0)\n",
      "Requirement already satisfied: gast>=0.3.2 in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-probability) (0.4.0)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-probability) (2.2.0)\n",
      "Requirement already satisfied: absl-py in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-probability) (1.3.0)\n",
      "Requirement already satisfied: dm-tree in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-probability) (0.1.8)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-probability) (1.24.1)\n",
      "Requirement already satisfied: imageio in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (2.23.0)\n",
      "Requirement already satisfied: numpy in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from imageio) (1.24.1)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from imageio) (9.3.0)\n",
      "Collecting git+https://github.com/tensorflow/docs\n",
      "  Cloning https://github.com/tensorflow/docs to /private/var/folders/zf/p75y8jj52c72dh5cv6ys92pm0000gn/T/pip-req-build-aff5ms3z\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/docs /private/var/folders/zf/p75y8jj52c72dh5cv6ys92pm0000gn/T/pip-req-build-aff5ms3z\n",
      "  Resolved https://github.com/tensorflow/docs to commit 476e61b24de218a85fbd71edffdd314c3c6a8b61\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: astor in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-docs==0.0.0.dev0) (0.8.1)\n",
      "Requirement already satisfied: absl-py in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-docs==0.0.0.dev0) (1.3.0)\n",
      "Requirement already satisfied: jinja2 in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-docs==0.0.0.dev0) (3.1.2)\n",
      "Requirement already satisfied: nbformat in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-docs==0.0.0.dev0) (5.7.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.12.0 in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-docs==0.0.0.dev0) (3.19.6)\n",
      "Requirement already satisfied: pyyaml in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-docs==0.0.0.dev0) (6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from jinja2->tensorflow-docs==0.0.0.dev0) (2.1.1)\n",
      "Requirement already satisfied: fastjsonschema in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (2.16.2)\n",
      "Requirement already satisfied: jupyter-core in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (5.1.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (4.17.3)\n",
      "Requirement already satisfied: traitlets>=5.1 in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from nbformat->tensorflow-docs==0.0.0.dev0) (5.8.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==0.0.0.dev0) (22.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==0.0.0.dev0) (0.19.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from jupyter-core->nbformat->tensorflow-docs==0.0.0.dev0) (2.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-probability\n",
    "!pip install imageio\n",
    "!pip install git+https://github.com/tensorflow/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ccc4b9c-4e69-4d2a-8da1-60ac5e7de1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_datasets in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (4.8.1)\n",
      "Requirement already satisfied: dill in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow_datasets) (0.3.6)\n",
      "Requirement already satisfied: six in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow_datasets) (1.16.0)\n",
      "Requirement already satisfied: click in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow_datasets) (8.1.3)\n",
      "Requirement already satisfied: tqdm in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow_datasets) (4.64.1)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow_datasets) (3.19.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow_datasets) (2.28.1)\n",
      "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow_datasets) (0.9.0)\n",
      "Requirement already satisfied: psutil in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow_datasets) (5.9.4)\n",
      "Requirement already satisfied: toml in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow_datasets) (0.10.2)\n",
      "Requirement already satisfied: numpy in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow_datasets) (1.24.1)\n",
      "Requirement already satisfied: termcolor in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow_datasets) (2.1.1)\n",
      "Requirement already satisfied: promise in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: absl-py in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow_datasets) (1.3.0)\n",
      "Requirement already satisfied: tensorflow-metadata in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow_datasets) (1.12.0)\n",
      "Requirement already satisfied: dm-tree in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow_datasets) (0.1.8)\n",
      "Requirement already satisfied: zipp in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (3.11.0)\n",
      "Requirement already satisfied: importlib_resources in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (5.10.2)\n",
      "Requirement already satisfied: typing_extensions in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.1.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /Users/ignaciomoyaredondo/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow-metadata->tensorflow_datasets) (1.57.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "357a190f-95b0-4fbd-848a-3f8866a9e979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa0cc59-5f79-438c-ab10-7f5c84deb640",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7124e82-1849-43f4-b2fa-13df0c044de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, _), (test_images, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f219a37-ea11-45b1-b8b9-493329de9b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_images[:50_000] / 255.\n",
    "X_val = train_images[50_000:] / 255.\n",
    "X_test = test_images / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b165afb-9ab7-4720-a141-66775d54d780",
   "metadata": {},
   "source": [
    "### Keras example\n",
    "https://keras.io/examples/generative/vae/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92485ea1-2c78-4fcf-b720-88b49a480f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        epsilon = tf.keras.backend.random_normal(tf.shape(z_log_var))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fc6e04-f681-4f16-b067-d64a1fa46fe4",
   "metadata": {},
   "source": [
    "##### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81264afd-8617-4762-9d88-177e615579a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 28, 28)]     0           []                               \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 784)          0           ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 160)          125600      ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 80)           12880       ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 40)           3240        ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 20)           820         ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 20)           820         ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " sampling_3 (Sampling)          (None, 20)           0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,360\n",
      "Trainable params: 143,360\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 20\n",
    "\n",
    "encoder_inputs = keras.Input(shape=[28, 28])\n",
    "x = layers.Flatten()(encoder_inputs)\n",
    "x = layers.Dense(160, activation=\"relu\")(x)\n",
    "x = layers.Dense(80, activation=\"relu\")(x)\n",
    "x = layers.Dense(40, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e138809b-9d44-4477-8999-a83ea16d8b44",
   "metadata": {},
   "source": [
    "##### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "baf62b30-c4b9-4a6b-90bd-2a237938c51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 40)                840       \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 80)                3280      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 160)               12960     \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 784)               126224    \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 28, 28)            0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 143,304\n",
      "Trainable params: 143,304\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = keras.Input(shape=[latent_dim])\n",
    "x = layers.Dense(40, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Dense(80, activation=\"relu\")(x)\n",
    "x = layers.Dense(160, activation=\"relu\")(x)\n",
    "x = layers.Dense(28 * 28, activation=\"sigmoid\")(x)\n",
    "decoder_outputs = layers.Reshape([28, 28])(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3a0fbeb9-9832-45f4-8b3b-4216afccd530",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, z = encoder(encoder_inputs)\n",
    "reconstructions = decoder(z)\n",
    "variational_ae = keras.Model(inputs=[encoder_inputs], outputs=[reconstructions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c802b5ab-100d-45f1-bb01-d0f9bd4a460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_loss = -0.5 * keras.backend.sum(1 + z_log_var - keras.backend.square(z_mean) - keras.backend.exp(z_log_var), axis=-1)\n",
    "variational_ae.add_loss(keras.backend.mean(latent_loss)/784)\n",
    "variational_ae.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ae021f1-f031-49d3-af89-a8c6d19f7dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "391/391 [==============================] - 4s 7ms/step - loss: 0.2800 - val_loss: 0.2484\n",
      "Epoch 2/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2407 - val_loss: 0.2315\n",
      "Epoch 3/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2269 - val_loss: 0.2166\n",
      "Epoch 4/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2123 - val_loss: 0.2055\n",
      "Epoch 5/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2015 - val_loss: 0.1965\n",
      "Epoch 6/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1925 - val_loss: 0.1891\n",
      "Epoch 7/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1859 - val_loss: 0.1830\n",
      "Epoch 8/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1808 - val_loss: 0.1804\n",
      "Epoch 9/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1769 - val_loss: 0.1756\n",
      "Epoch 10/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1739 - val_loss: 0.1706\n",
      "Epoch 11/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1714 - val_loss: 0.1715\n",
      "Epoch 12/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1693 - val_loss: 0.1673\n",
      "Epoch 13/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1674 - val_loss: 0.1664\n",
      "Epoch 14/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1658 - val_loss: 0.1649\n",
      "Epoch 15/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1643 - val_loss: 0.1620\n",
      "Epoch 16/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1628 - val_loss: 0.1630\n",
      "Epoch 17/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1615 - val_loss: 0.1600\n",
      "Epoch 18/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1605 - val_loss: 0.1595\n",
      "Epoch 19/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1596 - val_loss: 0.1595\n",
      "Epoch 20/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1587 - val_loss: 0.1588\n",
      "Epoch 21/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1581 - val_loss: 0.1591\n",
      "Epoch 22/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1574 - val_loss: 0.1555\n",
      "Epoch 23/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1567 - val_loss: 0.1575\n",
      "Epoch 24/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1562 - val_loss: 0.1563\n",
      "Epoch 25/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1556 - val_loss: 0.1567\n",
      "Epoch 26/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1551 - val_loss: 0.1543\n",
      "Epoch 27/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1547 - val_loss: 0.1537\n",
      "Epoch 28/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1542 - val_loss: 0.1544\n",
      "Epoch 29/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1537 - val_loss: 0.1544\n",
      "Epoch 30/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1533 - val_loss: 0.1543\n",
      "Epoch 31/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1529 - val_loss: 0.1531\n",
      "Epoch 32/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1526 - val_loss: 0.1520\n",
      "Epoch 33/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1523 - val_loss: 0.1522\n",
      "Epoch 34/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1519 - val_loss: 0.1522\n",
      "Epoch 35/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1516 - val_loss: 0.1525\n",
      "Epoch 36/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1513 - val_loss: 0.1504\n",
      "Epoch 37/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1510 - val_loss: 0.1520\n",
      "Epoch 38/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1507 - val_loss: 0.1507\n",
      "Epoch 39/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1504 - val_loss: 0.1525\n",
      "Epoch 40/40\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1502 - val_loss: 0.1502\n"
     ]
    }
   ],
   "source": [
    "history = variational_ae.fit(X_train, X_train, epochs=40, batch_size=128, validation_data=[X_val, X_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d764f970-43f4-4285-9952-6befeb818bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_tensor = tf.random.normal([6, latent_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b5ff454-8a74-41ee-8a9a-5c7a86fb4fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = decoder(latent_tensor).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ae405b17-aad0-4041-868c-432ed151d3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cc779ac5-0538-4904-82e1-4b84cfe30ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "ax, fig = plt.subplot(6)\n",
    "for i in range(len(image)):\n",
    "    ax[i].imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d690dd7-ca7f-477f-b996-78e1c1fcc84d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Class for CVAE \n",
    "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/cvae.ipynb#scrollTo=VGLbvBEmjK0a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
